{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115ef7e4",
   "metadata": {},
   "source": [
    "<h1 style='background-color: BLACK; padding: 10px; color: white'> Zoopla </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e175e1e",
   "metadata": {},
   "source": [
    "<h1 style='background-color: BLACK; padding: 10px; color: white'> Sales </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b65328d",
   "metadata": {},
   "source": [
    "First things first, we will import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4062122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc57114",
   "metadata": {},
   "source": [
    "Next, we will load in the dataset containing the list of postcode for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1195321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_csv('London postcode districts.xlsx - PC DIST.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a82ab",
   "metadata": {},
   "source": [
    "Now, we will create a function called 'zoopla_sales' to scrap properties that are for sale on the Zoopla website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080b8952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoopla_sales(postcodes, Trans_type, website, df):\n",
    "    \"\"\"\n",
    "    This function scrapes property data from Rightmove for a given list of postcodes and transaction type,\n",
    "    and returns the data as a pandas DataFrame.\n",
    "\n",
    "    Arguments:\n",
    "    postcodes -- a list of postcodes for which to scrape property data\n",
    "    Trans_type -- the transaction type of the properties to be scraped ('sales' or 'rent')\n",
    "    website -- the name of the website being scraped (in this case, 'Rightmove')\n",
    "    df -- an empty pandas DataFrame to store the scraped data\n",
    "\n",
    "    Returns:\n",
    "    df1 -- a pandas DataFrame containing the scraped property data\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Set the path to the ChromeDriver executable\n",
    "    s = Service(\"C:\\\\Users\\\\user\\\\Downloads\\\\Set ups\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "    \n",
    "    # Launch the ChromeDriver with the specified service\n",
    "    driver = webdriver.Chrome(service= s)\n",
    "    \n",
    "    # Navigate to the specified URL \n",
    "    driver.get('https://www.zoopla.co.uk/') \n",
    "\n",
    "    # Maximize the window\n",
    "    time.sleep(2)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    # Find the search bar  \n",
    "    time.sleep(2.2)\n",
    "    #search = driver.find_element(By.XPATH, '/html/body/div[3]/div/div[1]/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/div/form/div/div[1]/div/div/div/div/div/div/input')\n",
    "    try:\n",
    "        search = driver.find_element(By.XPATH, \"//input[contains(@id,'downshift')]\")\n",
    "        search.send_keys(postcode)\n",
    "        time.sleep(1.3)\n",
    "    except:\n",
    "        search = driver.find_element(By.XPATH, \"//input[contains(@class,'_1qzmny55 _1ftx2fq8')]\")\n",
    "        search.send_keys(postcode)\n",
    "        time.sleep(1.3)\n",
    "    \n",
    "    \n",
    "    # Click the search button\n",
    "    time.sleep(1.5)   \n",
    "    driver.find_element(By.XPATH, \"//button[@class='x8jo560 x8jo562 x8jo56a _1ftx2fq8'][1]\").click()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Initialize empty lists for storing scraped data\n",
    "    Trans_type = []\n",
    "    address = []\n",
    "    types = []\n",
    "    bedrooms = []\n",
    "    bathrooms = []\n",
    "    prices = []\n",
    "    desc = []\n",
    "    date_added = []\n",
    "    agent_list = []\n",
    "    property_url = []\n",
    "    website = []\n",
    "    \n",
    "    # Create an empty dataframe to store the scraped data\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "     # Setting the page number to be 1 \n",
    "    i = 1\n",
    "    while True: \n",
    "        # Scrapping data for the required features in the first page\n",
    "        time.sleep(1) \n",
    "        print(\"{} {} {} {}\".format('scraping page', i,'from', postcode ))\n",
    "        \n",
    "        time.sleep(2.1)\n",
    "        try: \n",
    "            driver.find_element(By.XPATH, \"//*[contains(@class,'u94mg1 u94mg4 u94mg9')]\").click()\n",
    "            time.sleep(1.5)\n",
    "            \n",
    "        except:\n",
    "            time.sleep(1.0)\n",
    "            \n",
    "        time.sleep(1.4)    \n",
    "        address_list =driver.find_elements(By.XPATH, \"//h2[contains(@class,'_1ankud51 _1ftx2fq8')]\")\n",
    "        type_list =driver.find_elements(By.XPATH, \"//h3[contains(@class,'_1ankud52 _1ftx2fq9')]\")\n",
    "        bedroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[1]//span[2]\")\n",
    "        bathroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[3]//span[2]\")\n",
    "        price_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_170k6632 _1ftx2fq6')]\")\n",
    "        desc_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_1ankud53 _1ftx2fq9')]\")\n",
    "        date_added_list =driver.find_elements(By.XPATH, \"//li[contains(@class,'_18cib8e1')]\")\n",
    "        agent_list_list =driver.find_elements(By.XPATH, \"//img[contains(@class,'_12bxhf70')]\")\n",
    "        property_url_list = driver.current_url\n",
    "        Trans_type_list = Trans_type\n",
    "        website_list = website\n",
    "        for address_item, type_item, bedroom_item, bathroom_item, price_item, desc_item, date_added_item, agent_list_item in zip(address_list, type_list, bedroom_list, bathroom_list, price_list, desc_list, date_added_list, agent_list_list):\n",
    "            address.append(address_item.text)\n",
    "            types.append(type_item.text)\n",
    "            bedrooms.append(bedroom_item.text)\n",
    "            bathrooms.append(bathroom_item.text)\n",
    "            prices.append(price_item.text)\n",
    "            desc.append(desc_item.text)\n",
    "            date_added.append(date_added_item.text)\n",
    "            agent_list.append(agent_list_item.text)\n",
    "            property_url.append(property_url_list)\n",
    "            Trans_type.append(Trans_type_list)\n",
    "            website.append(website_list)\n",
    "\n",
    "\n",
    "        time.sleep(1.3)\n",
    "        # get the height of the page\n",
    "        page_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "\n",
    "        \n",
    "        # Cancel the pop-up window\n",
    "        j= i + 1\n",
    "        url = f'https://www.zoopla.co.uk/for-sale/property/{postcode}/?q={postcode}&search_source=home&pn={j}'\n",
    "        if len(address_list) or len(type_list) != 0:\n",
    "            driver.get(url)\n",
    "        else:\n",
    "            print('------------------------------- SCRAPING COMPLETED FOR ' + postcode)\n",
    "            break\n",
    "        \n",
    "            \n",
    "        #Increment the page number\n",
    "        i += 1\n",
    "        time.sleep(1)\n",
    "                \n",
    "        \n",
    "    # Create a dataframe to store data scrapped for each postcode    \n",
    "    df1 = pd.DataFrame({'Location': postcode, 'Tansaction_Type': 'Sales','Property_Type':types, 'Address' :address, 'Bedrooms': bedrooms, 'Bathrooms':bathrooms, 'Price':prices, 'Description': desc, 'Listing_Date':date_added, 'Agent':agent_list, 'Listing_Source': 'Zoopla', 'listing_URL':property_url})\n",
    "    df1.insert(0, 'Unique_Id', [f'{postcode}S{i+1:05d}ZP' for i in range(len(df1))])\n",
    "    print('Total numbers of properties available in ' + postcode + ' is ' + str(df1.shape[0]))\n",
    "\n",
    "     # Concat the dataframe obtain for all postcodes\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "    \n",
    "     # Return a dataframe\n",
    "    return df1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42071880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page 1 from WC1B\n",
      "scraping page 2 from WC1B\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1B\n",
      "Total numbers of properties available in WC1B is 13\n",
      "scraping page 1 from WC1E\n",
      "scraping page 2 from WC1E\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1E\n",
      "Total numbers of properties available in WC1E is 21\n",
      "scraping page 1 from WC1H\n",
      "scraping page 2 from WC1H\n",
      "scraping page 3 from WC1H\n",
      "scraping page 4 from WC1H\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1H\n",
      "Total numbers of properties available in WC1H is 40\n",
      "scraping page 1 from WC1N\n",
      "scraping page 2 from WC1N\n",
      "scraping page 3 from WC1N\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1N\n",
      "Total numbers of properties available in WC1N is 28\n",
      "scraping page 1 from WC1V\n",
      "scraping page 2 from WC1V\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1V\n",
      "Total numbers of properties available in WC1V is 10\n",
      "scraping page 1 from WC1X\n",
      "scraping page 2 from WC1X\n",
      "scraping page 3 from WC1X\n",
      "scraping page 4 from WC1X\n",
      "scraping page 5 from WC1X\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1X\n",
      "Total numbers of properties available in WC1X is 69\n",
      "scraping page 1 from WC2A\n",
      "scraping page 2 from WC2A\n",
      "scraping page 3 from WC2A\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2A\n",
      "Total numbers of properties available in WC2A is 25\n",
      "scraping page 1 from WC2B\n",
      "scraping page 2 from WC2B\n",
      "scraping page 3 from WC2B\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2B\n",
      "Total numbers of properties available in WC2B is 36\n",
      "scraping page 1 from WC2E\n",
      "scraping page 2 from WC2E\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2E\n",
      "Total numbers of properties available in WC2E is 19\n",
      "scraping page 1 from WC2H\n",
      "scraping page 2 from WC2H\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2H\n",
      "Total numbers of properties available in WC2H is 17\n",
      "scraping page 1 from WC2N\n",
      "scraping page 2 from WC2N\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2N\n",
      "Total numbers of properties available in WC2N is 22\n",
      "scraping page 1 from WC2R\n",
      "scraping page 2 from WC2R\n",
      "scraping page 3 from WC2R\n",
      "scraping page 4 from WC2R\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2R\n",
      "Total numbers of properties available in WC2R is 53\n",
      "------------------------ WEB SCRAPING COMPLETED: OVERALL TOTAL NUMBER OF PROPERTIES SCRAPED IS 353\n"
     ]
    }
   ],
   "source": [
    "# create an empty DataFrame outside the function\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# loop through postcodes\n",
    "for postcode in codes.loc[256:]['Postcode district']:\n",
    "    # call the function and pass the empty DataFrame as an argument\n",
    "    df1 = zoopla_sales(postcode, 'Sales', 'Zoopla', df)\n",
    "    # append the df1 DataFrame to the empty DataFrame\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "print('------------------------ WEB SCRAPING COMPLETED: OVERALL TOTAL NUMBER OF PROPERTIES SCRAPED IS ' + str(df.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e44cbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Zoopla_Sales_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6995853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postcode district</th>\n",
       "      <th>Local Areas</th>\n",
       "      <th>Borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>WC1B</td>\n",
       "      <td>Bloomsbury, British Museum</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>WC1E</td>\n",
       "      <td>University College London</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>WC1H</td>\n",
       "      <td>St Pancras</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>WC1N</td>\n",
       "      <td>Great Ormond Street Hospital</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>WC1V</td>\n",
       "      <td>High Holborn</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>WC1X</td>\n",
       "      <td>Kings Cross, Finsbury (west)</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>WC2A</td>\n",
       "      <td>Lincoln's Inn Fields, Royal Courts of Justice</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>WC2B</td>\n",
       "      <td>Drury Lane, Aldwych</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>WC2E</td>\n",
       "      <td>Covent Garden</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>WC2H</td>\n",
       "      <td>Leicester Square</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>WC2N</td>\n",
       "      <td>Charing Cross</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>WC2R</td>\n",
       "      <td>Somerset House</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Postcode district                                    Local Areas  \\\n",
       "256              WC1B                     Bloomsbury, British Museum   \n",
       "257              WC1E                      University College London   \n",
       "258              WC1H                                     St Pancras   \n",
       "259              WC1N                   Great Ormond Street Hospital   \n",
       "260              WC1V                                   High Holborn   \n",
       "261              WC1X                   Kings Cross, Finsbury (west)   \n",
       "262              WC2A  Lincoln's Inn Fields, Royal Courts of Justice   \n",
       "263              WC2B                            Drury Lane, Aldwych   \n",
       "264              WC2E                                  Covent Garden   \n",
       "265              WC2H                               Leicester Square   \n",
       "266              WC2N                                  Charing Cross   \n",
       "267              WC2R                                 Somerset House   \n",
       "\n",
       "         Borough  \n",
       "256       Camden  \n",
       "257       Camden  \n",
       "258       Camden  \n",
       "259       Camden  \n",
       "260       Camden  \n",
       "261       Camden  \n",
       "262       Camden  \n",
       "263       Camden  \n",
       "264  Westminster  \n",
       "265  Westminster  \n",
       "266  Westminster  \n",
       "267  Westminster  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = codes.loc[256:]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "20ecf0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6 bed semi-detached house for sale', '1 bed flat for sale', '2 bed flat for sale', '3 bed terraced house for sale', '3 bed semi-detached house for sale', '1 bed flat for sale', '2 bed terraced house for sale', '5 bed detached house for sale', '3 bed link detached house for sale', '5 bed detached house for sale', '5 bed detached house for sale', 'Land for sale', '5 bed property for sale', '4 bed detached house for sale', '2 bed terraced house for sale', '6 bed detached house for sale', '3 bed flat for sale', '1 bed flat for sale', '3 bed terraced house for sale', '4 bed detached house for sale', '3 bed terraced house for sale', '3 bed terraced house for sale', '2 bed semi-detached bungalow for sale', '4 bed detached house for sale', '2 bed end terrace house for sale']\n",
      "['Bishops Avenue, Bromley, Kent BR1', 'College Road, Bromley BR1', 'Marian Gardens, Bromley, Kent BR1', 'Forde Avenue, Bromley, Kent BR1', 'Ellen Close, Bickley, Bromley BR1', 'South Street, Bromley BR1', 'Rangefield Road, Bromley BR1', 'Southborough Road, Bickley, Bromley BR1', 'Powster Road, Bromley BR1', 'Sundridge Avenue, Bromley BR1', 'Woodlands Close, Bromley BR1', 'Ethelbert Close, Bromley BR1', 'Southborough Road, Bickley, Bromley BR1', 'Westcott Close, Bromley BR1', 'Farrier Close, Bromley BR1', 'Timms Close, Bromley, Kent BR1', '28 Oaklands Road, Bromley BR1', 'Babbacombe Road, Bromley BR1', 'Brangbourne Road, Bromley, Kent BR1', 'Widmore Road, Bromley BR1', 'Plymouth Road, Bromley BR1', 'Brangbourne Road, Bromley BR1', 'Welbeck Avenue, Bromley BR1', 'Highland Road, Bromley, Kent BR1', 'Wharton Road, Bromley BR1']\n",
      "['6', '1', '2', '3', '3', '1', '2', '5', '3', '5', '5', '5', '4', '2', '6', '3', '1', '3', '4', '3', '3', '2', '4', '2']\n",
      "['2', '1', '1', '1', '2', '1', '1', '3', '1', '3', '3', '4', '1', '3', '1', '1', '2', '2', '1', '2', '1', '1']\n",
      "['£1,250,000', '£255,000', '£550,000', '£600,000', '£525,000', '£260,000', '£400,000', '£1,000,000', '£600,000', '£2,750,000', '£1,500,000', '£15,000', '£1,000,000', '£1,400,000', '£475,000', '£2,250,000', '£490,000', '£300,000', '£499,995', '£1,500,000', '£475,000', '£650,000', '£399,950', '£875,000', '£500,000']\n",
      "['Chain free and newly rennovated to an exceptional standard - a fabulous 6-bed, 3.5-Bath property in the sought after Bishops Avenue, Bromley. Open ...', 'Escape the city hustle with this stunning one-bedroom garden flat in Bromley, featuring a private outdoor oasis, luxurious bathroom, and short ...', 'Located in the prestigious Hampton Grange development in Sundridge Park and presented in stunning condition is this two double bedroom second ...', \"A very generously proportioned mid terraced three bedroom 1930's family house requiring modernisation and redecoration, which is amply reflected ...\", '*Guide Price £525,000 - £550,000* A spacious three bedroom 1970’s semi-detached house situated within a quiet cul-de-sac in the heart of Bromley ...', '** Guide Price £260,000 to £280,000 ** Leaders are pleased to present to the market this chain free one double bedroom apartment, that we feel is ...', 'A well presented three bedroom mid-terrace house situated in a quiet, residential road, ideally located for Bromley town centre. Benefitting from ...', 'Opportunity to acquire a self-build plot with planning permission pending (renewal of existing consent) for a sizable detached family residence ...', 'New to Market: Modern, Spacious and Beautifully designed newly refurbished family home with high ceilings and large back garden and a drive, with ...', 'Beautifully designed to reflect the elegant features of a Georgian villa, which was built in 2016 measuring 4995 square feet. The internal ...', 'Ref pb 0330', 'Strapline Auction Sale - 31/05/2023 A unexcavated basement space with planning permission granted for excavation of the ground to front, side and ...', 'An rare opportunity to acquire a self-build plot with planning permission pending (renewal of existing consent) for a sizable detached family ...', 'Extremely well presented, four bedroom detached property.', 'A well-presented, modern 1990s built, two double bedroom property set in a quite cul-de-sac location. The property boasts: Cloakroom, reception ...', 'Guide price £2,250,000 - £2,500,000. Chain free. Full video tour. Located just 0.4 miles from Bickley station is this superb and truly unique ...', 'A well-presented three bedroom first floor apartment (1,019sqft) situated in a highly popular area of Bromley. With its high ceilings, the ...', 'Located on a residential road in Bromley town centre is this spacious one double bedroom ground floor apartment. Energy Efficiency Rating D.', 'Capital Estate Agents are pleased to offer to the market this solid 1930s mid terrace property located on a popular residential road, within close ...', 'This elegant 4 bedroom detached house boasts ample living with 2 bright reception rooms, modern kitchen, 3 stylish bathrooms, lovely south-facing ...', '**Guide Price £475,000 to £500,000** Offered to the market Chain Free and located in the heart of the much sought after Bromley Old Town is this ...', 'Beautiful 3 bedroom house in a cul-de-sac with front and rear gardens, conservatory, garage. Close to Beckenham British Rail. 20 minutes to London ...', '*** chain free *** Nestled in the heart of Bromley, this charming 2-bedroom semi-detached bungalow eagerly awaits its next owner to unleash its ...', 'Capital Estate Agents are pleased to offer to the market this detached new build house located on its own secluded plot, offered chain free and ...', \"A charming, two bedroom, end of terrace, halls adjoining cottage centrally located in the highly sought after 'Bromley Old Town' with its range of ...\"]\n",
      "['Listed on 18th May 2023', 'Listed on 18th May 2023', 'Listed on 18th May 2023', 'Listed on 18th May 2023', 'Listed on 18th May 2023', 'Available immediately', 'Listed on 17th May 2023', 'Listed on 17th May 2023', 'Listed on 17th May 2023', 'Listed on 17th May 2023', 'Listed on 17th May 2023', 'Available immediately', 'Listed on 17th May 2023', 'Listed on 16th May 2023', 'Listed on 16th May 2023', 'Listed on 16th May 2023', 'Listed on 16th May 2023', 'Listed on 16th May 2023', 'Listed on 15th May 2023', 'Listed on 15th May 2023', 'Available immediately', 'Listed on 15th May 2023', 'Listed on 15th May 2023', 'Listed on 15th May 2023', 'Listed on 15th May 2023', 'Listed on 15th May 2023', 'Listed on 15th May 2023', 'Listed on 15th May 2023']\n",
      "['Keller Williams Advantage', '1st Choice Estates Ltd', 'Sinclair Hammelton - Bromley Sales', 'Sinclair Hammelton - Bromley Sales', 'Langford Russell - Bromley', 'Leaders - Beckenham', 'Purplebricks, Head Office', 'Hunters - Chislehurst and Bromley', 'Yopa', 'Langford Russell - Bromley', 'eXp World UK', 'Savills - National Auctions', 'Hunters - Chislehurst and Bromley', 'jdm Estate Agents', 'Alan De Maid - Bromley', 'Nested Ltd', 'Purplebricks, Head Office', 'Langford Russell - Bromley', 'Capital Bromley', 'Foxtons - Bromley', 'jdm Estate Agents', 'Panther International Properties', 'Cockburn Estate Agents', 'Capital Bromley', 'Alan De Maid - Bromley']\n",
      "25\n",
      "25\n",
      "24\n",
      "22\n",
      "25\n",
      "25\n",
      "28\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Set the path to the ChromeDriver executable\n",
    "s = Service(\"C:\\\\Users\\\\user\\\\Downloads\\\\Set ups\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "\n",
    "# Launch the ChromeDriver with the specified service\n",
    "driver = webdriver.Chrome(service= s)\n",
    "\n",
    "# Navigate to the specified URL \n",
    "driver.get('https://www.zoopla.co.uk/') \n",
    "\n",
    "# Click to cancel the pop-up window and maximize the window\n",
    "#driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div/div/div[2]/button').click()\n",
    "time.sleep(2)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Find the search bar  \n",
    "time.sleep(1.2)\n",
    "search = driver.find_element(By.XPATH, '/html/body/div[3]/div/div[1]/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/div/form/div/div[1]/div/div/div/div/div/div/input')\n",
    "search.send_keys('BR1')\n",
    "time.sleep(1.3)\n",
    "\n",
    "# Click the search button\n",
    "time.sleep(3)\n",
    "driver.find_element(By.XPATH, '/html/body/div[3]/div/div[1]/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/div/form/div/div[2]/button').click()\n",
    "\n",
    "time.sleep(3)\n",
    "Trans_type = []\n",
    "address = []\n",
    "types = []\n",
    "bedrooms = []\n",
    "bathrooms = []\n",
    "prices = []\n",
    "desc = []\n",
    "date_added = []\n",
    "agent_list = []\n",
    "property_url = []\n",
    "website = []\n",
    "\n",
    "address_list =driver.find_elements(By.XPATH, \"//h2[contains(@class,'_1ankud51 _1ftx2fq8')]\")\n",
    "type_list =driver.find_elements(By.XPATH, \"//h3[contains(@class,'_1ankud52 _1ftx2fq9')]\")\n",
    "bedroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[1]//span[2]\")\n",
    "bathroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[3]//span[2]\")\n",
    "price_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_170k6632 _1ftx2fq6')]\")\n",
    "desc_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_1ankud53 _1ftx2fq9')]\")\n",
    "date_added_list =driver.find_elements(By.XPATH, \"//li[contains(@class,'_18cib8e1')]\")\n",
    "agent_list_list =driver.find_elements(By.XPATH, \"//img[contains(@class,'_12bxhf70')]\")\n",
    "\n",
    "for ad in address_list:\n",
    "    address.append(ad.text)\n",
    "print(address)\n",
    "\n",
    "                          \n",
    "for ad in type_list:\n",
    "    types.append(ad.text)\n",
    "print(types)                                  \n",
    "\n",
    "for ad in bedroom_list:\n",
    "    bedrooms.append(ad.text)\n",
    "print(bedrooms)\n",
    "                              \n",
    "for ad in bathroom_list:\n",
    "    bathrooms.append(ad.text)\n",
    "print(bathrooms)\n",
    "\n",
    "\n",
    "for ad in price_list:\n",
    "    prices.append(ad.text)\n",
    "print(prices)\n",
    "\n",
    "\n",
    "for ad in desc_list:\n",
    "    desc.append(ad.text)\n",
    "print(desc)\n",
    "\n",
    "\n",
    "for ad in date_added_list:\n",
    "    date_added.append(ad.text)\n",
    "print(date_added)\n",
    "\n",
    "for ad in agent_list_list:\n",
    "    agent_list.append(ad.get_attribute('alt'))\n",
    "print(agent_list)\n",
    "\n",
    "print(len(address))\n",
    "print(len(types))\n",
    "print(len(bedrooms))\n",
    "print(len(bathrooms))\n",
    "print(len(prices))\n",
    "print(len(desc))\n",
    "print(len(date_added))\n",
    "print(len(agent_list))\n",
    "\n",
    "url = 'https://www.zoopla.co.uk/for-sale/property/br1/?q=BR1&search_source=home&pn=2'\n",
    "if len(address_list) and len(type_list) != 0:\n",
    "    driver.get(url)\n",
    "else:\n",
    "    print('------------------------------- SCRAPING COMPLETED FOR ' + postcode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72edbcd",
   "metadata": {},
   "source": [
    "<h1 style='background-color: BLACK; padding: 10px; color: white'> Rent </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c5be01",
   "metadata": {},
   "source": [
    "Now, we will create a function called 'zoopla_rent' to scrap properties that are for rent on the Zoopla website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91431634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoopla_rent(postcodes, Trans_type, website, df):\n",
    "    \"\"\"\n",
    "    This function scrapes property data from Rightmove for a given list of postcodes and transaction type,\n",
    "    and returns the data as a pandas DataFrame.\n",
    "\n",
    "    Arguments:\n",
    "    postcodes -- a list of postcodes for which to scrape property data\n",
    "    Trans_type -- the transaction type of the properties to be scraped ('sales' or 'rent')\n",
    "    website -- the name of the website being scraped (in this case, 'Rightmove')\n",
    "    df -- an empty pandas DataFrame to store the scraped data\n",
    "\n",
    "    Returns:\n",
    "    df1 -- a pandas DataFrame containing the scraped property data\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Set the path to the ChromeDriver executable\n",
    "    s = Service(\"C:\\\\Users\\\\user\\\\Downloads\\\\Set ups\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "    \n",
    "    # Launch the ChromeDriver with the specified service\n",
    "    driver = webdriver.Chrome(service= s)\n",
    "    \n",
    "    # Navigate to the specified URL \n",
    "    driver.get('https://www.zoopla.co.uk/') \n",
    "\n",
    "    # Maximize the window\n",
    "    time.sleep(2)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    #Click the rent button\n",
    "    time.sleep(1.5)   \n",
    "    driver.find_element(By.XPATH, \"//button[contains(@id,'radix-:Reckt6:-trigger-to-rent')]\").click()\n",
    "\n",
    "    # Find the search bar  \n",
    "    time.sleep(2.2)\n",
    "    #search = driver.find_element(By.XPATH, '/html/body/div[3]/div/div[1]/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/div/form/div/div[1]/div/div/div/div/div/div/input')\n",
    "    try:\n",
    "        search = driver.find_element(By.XPATH, \"//input[contains(@id,'downshift')]\")\n",
    "        search.send_keys(postcode)\n",
    "        time.sleep(1.3)\n",
    "    except:\n",
    "        search = driver.find_element(By.XPATH, \"//input[contains(@class,'_1qzmny55 _1ftx2fq8')]\")\n",
    "        search.send_keys(postcode)\n",
    "        time.sleep(1.3)\n",
    "    \n",
    "    \n",
    "    # Click the search button\n",
    "    time.sleep(1.5)   \n",
    "    driver.find_element(By.XPATH, \"//button[@class='x8jo560 x8jo562 x8jo56a _1ftx2fq8'][1]\").click()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Initialize empty lists for storing scraped data\n",
    "    Trans_type = []\n",
    "    address = []\n",
    "    types = []\n",
    "    bedrooms = []\n",
    "    bathrooms = []\n",
    "    prices = []\n",
    "    desc = []\n",
    "    date_added = []\n",
    "    agent_list = []\n",
    "    property_url = []\n",
    "    website = []\n",
    "    \n",
    "    # Create an empty dataframe to store the scraped data\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "     # Setting the page number to be 1 \n",
    "    i = 1\n",
    "    while True: \n",
    "        # Scrapping data for the required features in the first page\n",
    "        time.sleep(1) \n",
    "        print(\"{} {} {} {}\".format('scraping page', i,'from', postcode ))\n",
    "        \n",
    "        time.sleep(2.1)\n",
    "        try: \n",
    "            driver.find_element(By.XPATH, \"//*[contains(@class,'u94mg1 u94mg4 u94mg9')]\").click()\n",
    "            time.sleep(1.5)\n",
    "            \n",
    "        except:\n",
    "            time.sleep(1.0)\n",
    "            \n",
    "        time.sleep(1.4)    \n",
    "        address_list =driver.find_elements(By.XPATH, \"//h2[contains(@class,'_1ankud51 _1ftx2fq8')]\")\n",
    "        type_list =driver.find_elements(By.XPATH, \"//h3[contains(@class,'_1ankud52 _1ftx2fq9')]\")\n",
    "        bedroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[1]//span[2]\")\n",
    "        bathroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[3]//span[2]\")\n",
    "        price_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_170k6632 _1ftx2fq6')]\")\n",
    "        desc_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_1ankud53 _1ftx2fq9')]\")\n",
    "        date_added_list =driver.find_elements(By.XPATH, \"//li[contains(@class,'_18cib8e1')]\")\n",
    "        agent_list_list =driver.find_elements(By.XPATH, \"//img[contains(@class,'_12bxhf70')]\")\n",
    "        property_url_list = driver.current_url\n",
    "        Trans_type_list = Trans_type\n",
    "        website_list = website\n",
    "        for address_item, type_item, bedroom_item, bathroom_item, price_item, desc_item, date_added_item, agent_list_item in zip(address_list, type_list, bedroom_list, bathroom_list, price_list, desc_list, date_added_list, agent_list_list):\n",
    "            address.append(address_item.text)\n",
    "            types.append(type_item.text)\n",
    "            bedrooms.append(bedroom_item.text)\n",
    "            bathrooms.append(bathroom_item.text)\n",
    "            prices.append(price_item.text)\n",
    "            desc.append(desc_item.text)\n",
    "            date_added.append(date_added_item.text)\n",
    "            agent_list.append(agent_list_item.text)\n",
    "            property_url.append(property_url_list)\n",
    "            Trans_type.append(Trans_type_list)\n",
    "            website.append(website_list)\n",
    "\n",
    "\n",
    "        time.sleep(1.3)\n",
    "        # get the height of the page\n",
    "        page_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "\n",
    "        \n",
    "        # Cancel the pop-up window\n",
    "        j= i + 1        \n",
    "        url = f'https://www.zoopla.co.uk/to-rent/property/{postcode}/?price_frequency=per_month&q={postcode}&search_source=home&pn={j}'\n",
    "        if len(address_list) or len(type_list) != 0:\n",
    "            driver.get(url)\n",
    "        else:\n",
    "            print('------------------------------- SCRAPING COMPLETED FOR ' + postcode)\n",
    "            break\n",
    "        \n",
    "            \n",
    "        #Increment the page number\n",
    "        i += 1\n",
    "        time.sleep(1)\n",
    "                \n",
    "        \n",
    "    # Create a dataframe to store data scrapped for each postcode    \n",
    "    df1 = pd.DataFrame({'Location': postcode, 'Tansaction_Type': 'Rent','Property_Type':types, 'Address' :address, 'Bedrooms': bedrooms, 'Bathrooms':bathrooms, 'Price':prices, 'Description': desc, 'Listing_Date':date_added, 'Agent':agent_list, 'Listing_Source': 'Zoopla', 'listing_URL':property_url})\n",
    "    df1.insert(0, 'Unique_Id', [f'{postcode}R{i+1:05d}ZP' for i in range(len(df1))])\n",
    "    print('Total numbers of properties available in ' + postcode + ' is ' + str(df1.shape[0]))\n",
    "\n",
    "     # Concat the dataframe obtain for all postcodes\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "    \n",
    "     # Return a dataframe\n",
    "    return df1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29b459a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page 1 from HA2\n",
      "scraping page 2 from HA2\n",
      "scraping page 3 from HA2\n",
      "scraping page 4 from HA2\n",
      "scraping page 5 from HA2\n",
      "------------------------------- SCRAPING COMPLETED FOR HA2\n",
      "Total numbers of properties available in HA2 is 48\n",
      "scraping page 1 from HA3\n",
      "scraping page 2 from HA3\n",
      "scraping page 3 from HA3\n",
      "scraping page 4 from HA3\n",
      "scraping page 5 from HA3\n",
      "------------------------------- SCRAPING COMPLETED FOR HA3\n",
      "Total numbers of properties available in HA3 is 43\n",
      "scraping page 1 from HA4\n",
      "scraping page 2 from HA4\n",
      "scraping page 3 from HA4\n",
      "------------------------------- SCRAPING COMPLETED FOR HA4\n",
      "Total numbers of properties available in HA4 is 23\n",
      "scraping page 1 from HA5\n",
      "scraping page 2 from HA5\n",
      "scraping page 3 from HA5\n",
      "scraping page 4 from HA5\n",
      "------------------------------- SCRAPING COMPLETED FOR HA5\n",
      "Total numbers of properties available in HA5 is 49\n",
      "scraping page 1 from HA6\n",
      "scraping page 2 from HA6\n",
      "scraping page 3 from HA6\n",
      "scraping page 4 from HA6\n",
      "------------------------------- SCRAPING COMPLETED FOR HA6\n",
      "Total numbers of properties available in HA6 is 42\n",
      "scraping page 1 from HA7\n",
      "scraping page 2 from HA7\n",
      "scraping page 3 from HA7\n",
      "scraping page 4 from HA7\n",
      "------------------------------- SCRAPING COMPLETED FOR HA7\n",
      "Total numbers of properties available in HA7 is 48\n",
      "scraping page 1 from HA8\n",
      "scraping page 2 from HA8\n",
      "scraping page 3 from HA8\n",
      "scraping page 4 from HA8\n",
      "scraping page 5 from HA8\n",
      "------------------------------- SCRAPING COMPLETED FOR HA8\n",
      "Total numbers of properties available in HA8 is 49\n",
      "scraping page 1 from HA9\n",
      "scraping page 2 from HA9\n",
      "scraping page 3 from HA9\n",
      "scraping page 4 from HA9\n",
      "scraping page 5 from HA9\n",
      "scraping page 6 from HA9\n",
      "scraping page 7 from HA9\n",
      "scraping page 8 from HA9\n",
      "scraping page 9 from HA9\n",
      "scraping page 10 from HA9\n",
      "scraping page 11 from HA9\n",
      "scraping page 12 from HA9\n",
      "scraping page 13 from HA9\n",
      "------------------------------- SCRAPING COMPLETED FOR HA9\n",
      "Total numbers of properties available in HA9 is 84\n",
      "scraping page 1 from IG1\n",
      "scraping page 2 from IG1\n",
      "scraping page 3 from IG1\n",
      "scraping page 4 from IG1\n",
      "scraping page 5 from IG1\n",
      "------------------------------- SCRAPING COMPLETED FOR IG1\n",
      "Total numbers of properties available in IG1 is 64\n",
      "scraping page 1 from IG11\n",
      "scraping page 2 from IG11\n",
      "scraping page 3 from IG11\n",
      "scraping page 4 from IG11\n",
      "------------------------------- SCRAPING COMPLETED FOR IG11\n",
      "Total numbers of properties available in IG11 is 28\n",
      "scraping page 1 from IG2\n",
      "scraping page 2 from IG2\n",
      "scraping page 3 from IG2\n",
      "------------------------------- SCRAPING COMPLETED FOR IG2\n",
      "Total numbers of properties available in IG2 is 26\n",
      "scraping page 1 from IG3\n",
      "scraping page 2 from IG3\n",
      "scraping page 3 from IG3\n",
      "------------------------------- SCRAPING COMPLETED FOR IG3\n",
      "Total numbers of properties available in IG3 is 25\n",
      "scraping page 1 from IG4\n",
      "scraping page 2 from IG4\n",
      "------------------------------- SCRAPING COMPLETED FOR IG4\n",
      "Total numbers of properties available in IG4 is 7\n",
      "scraping page 1 from IG5\n",
      "scraping page 2 from IG5\n",
      "------------------------------- SCRAPING COMPLETED FOR IG5\n",
      "Total numbers of properties available in IG5 is 9\n",
      "scraping page 1 from IG6\n",
      "scraping page 2 from IG6\n",
      "scraping page 3 from IG6\n",
      "------------------------------- SCRAPING COMPLETED FOR IG6\n",
      "Total numbers of properties available in IG6 is 19\n",
      "scraping page 1 from IG7\n",
      "scraping page 2 from IG7\n",
      "scraping page 3 from IG7\n",
      "------------------------------- SCRAPING COMPLETED FOR IG7\n",
      "Total numbers of properties available in IG7 is 25\n",
      "scraping page 1 from IG8\n",
      "scraping page 2 from IG8\n",
      "scraping page 3 from IG8\n",
      "------------------------------- SCRAPING COMPLETED FOR IG8\n",
      "Total numbers of properties available in IG8 is 33\n",
      "scraping page 1 from IG9\n",
      "scraping page 2 from IG9\n",
      "------------------------------- SCRAPING COMPLETED FOR IG9\n",
      "Total numbers of properties available in IG9 is 11\n",
      "scraping page 1 from KT1\n",
      "scraping page 2 from KT1\n",
      "scraping page 3 from KT1\n",
      "scraping page 4 from KT1\n",
      "scraping page 5 from KT1\n",
      "scraping page 6 from KT1\n",
      "scraping page 7 from KT1\n",
      "------------------------------- SCRAPING COMPLETED FOR KT1\n",
      "Total numbers of properties available in KT1 is 115\n",
      "scraping page 1 from KT17\n",
      "scraping page 2 from KT17\n",
      "scraping page 3 from KT17\n",
      "------------------------------- SCRAPING COMPLETED FOR KT17\n",
      "Total numbers of properties available in KT17 is 21\n",
      "scraping page 1 from KT19\n",
      "scraping page 2 from KT19\n",
      "scraping page 3 from KT19\n",
      "------------------------------- SCRAPING COMPLETED FOR KT19\n",
      "Total numbers of properties available in KT19 is 21\n",
      "scraping page 1 from KT2\n",
      "scraping page 2 from KT2\n",
      "scraping page 3 from KT2\n",
      "scraping page 4 from KT2\n",
      "------------------------------- SCRAPING COMPLETED FOR KT2\n",
      "Total numbers of properties available in KT2 is 55\n",
      "scraping page 1 from KT3\n",
      "scraping page 2 from KT3\n",
      "scraping page 3 from KT3\n",
      "scraping page 4 from KT3\n",
      "------------------------------- SCRAPING COMPLETED FOR KT3\n",
      "Total numbers of properties available in KT3 is 49\n",
      "scraping page 1 from KT4\n",
      "scraping page 2 from KT4\n",
      "scraping page 3 from KT4\n",
      "------------------------------- SCRAPING COMPLETED FOR KT4\n",
      "Total numbers of properties available in KT4 is 18\n",
      "scraping page 1 from KT5\n",
      "scraping page 2 from KT5\n",
      "scraping page 3 from KT5\n",
      "------------------------------- SCRAPING COMPLETED FOR KT5\n",
      "Total numbers of properties available in KT5 is 17\n",
      "scraping page 1 from KT6\n",
      "scraping page 2 from KT6\n",
      "scraping page 3 from KT6\n",
      "scraping page 4 from KT6\n",
      "------------------------------- SCRAPING COMPLETED FOR KT6\n",
      "Total numbers of properties available in KT6 is 46\n",
      "scraping page 1 from KT8\n",
      "scraping page 2 from KT8\n",
      "scraping page 3 from KT8\n",
      "------------------------------- SCRAPING COMPLETED FOR KT8\n",
      "Total numbers of properties available in KT8 is 24\n",
      "scraping page 1 from KT9\n",
      "scraping page 2 from KT9\n",
      "------------------------------- SCRAPING COMPLETED FOR KT9\n",
      "Total numbers of properties available in KT9 is 14\n",
      "scraping page 1 from N1\n",
      "scraping page 2 from N1\n",
      "scraping page 3 from N1\n",
      "scraping page 4 from N1\n",
      "scraping page 5 from N1\n",
      "scraping page 6 from N1\n",
      "scraping page 7 from N1\n",
      "scraping page 8 from N1\n",
      "scraping page 9 from N1\n",
      "scraping page 10 from N1\n",
      "scraping page 11 from N1\n",
      "scraping page 12 from N1\n",
      "scraping page 13 from N1\n",
      "scraping page 14 from N1\n",
      "scraping page 15 from N1\n",
      "scraping page 16 from N1\n",
      "scraping page 17 from N1\n",
      "scraping page 18 from N1\n",
      "scraping page 19 from N1\n",
      "scraping page 20 from N1\n",
      "scraping page 21 from N1\n",
      "scraping page 22 from N1\n",
      "------------------------------- SCRAPING COMPLETED FOR N1\n",
      "Total numbers of properties available in N1 is 370\n",
      "scraping page 1 from N10\n",
      "scraping page 2 from N10\n",
      "scraping page 3 from N10\n",
      "scraping page 4 from N10\n",
      "------------------------------- SCRAPING COMPLETED FOR N10\n",
      "Total numbers of properties available in N10 is 38\n",
      "scraping page 1 from N11\n",
      "scraping page 2 from N11\n",
      "scraping page 3 from N11\n",
      "scraping page 4 from N11\n",
      "------------------------------- SCRAPING COMPLETED FOR N11\n",
      "Total numbers of properties available in N11 is 45\n",
      "scraping page 1 from N12\n",
      "scraping page 2 from N12\n",
      "scraping page 3 from N12\n",
      "scraping page 4 from N12\n",
      "scraping page 5 from N12\n",
      "scraping page 6 from N12\n",
      "------------------------------- SCRAPING COMPLETED FOR N12\n",
      "Total numbers of properties available in N12 is 61\n",
      "scraping page 1 from N13\n",
      "scraping page 2 from N13\n",
      "scraping page 3 from N13\n",
      "scraping page 4 from N13\n",
      "------------------------------- SCRAPING COMPLETED FOR N13\n",
      "Total numbers of properties available in N13 is 34\n",
      "scraping page 1 from N14\n",
      "scraping page 2 from N14\n",
      "scraping page 3 from N14\n",
      "------------------------------- SCRAPING COMPLETED FOR N14\n",
      "Total numbers of properties available in N14 is 26\n",
      "scraping page 1 from N15\n",
      "------------------------------- SCRAPING COMPLETED FOR N15\n",
      "Total numbers of properties available in N15 is 0\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=113.0.5672.127)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x01088893+48451]\n\t(No symbol) [0x0101B8A1]\n\t(No symbol) [0x00F25058]\n\t(No symbol) [0x00F0D073]\n\t(No symbol) [0x00F6DEBB]\n\t(No symbol) [0x00F7BFD3]\n\t(No symbol) [0x00F6A0B6]\n\t(No symbol) [0x00F47E08]\n\t(No symbol) [0x00F48F2D]\n\tGetHandleVerifier [0x012E8E3A+2540266]\n\tGetHandleVerifier [0x01328959+2801161]\n\tGetHandleVerifier [0x0132295C+2776588]\n\tGetHandleVerifier [0x01112280+612144]\n\t(No symbol) [0x01024F6C]\n\t(No symbol) [0x010211D8]\n\t(No symbol) [0x010212BB]\n\t(No symbol) [0x01014857]\n\tBaseThreadInitThunk [0x750A00C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x76FE7B4E+286]\n\tRtlGetAppContainerNamedObjectPath [0x76FE7B1E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# loop through postcodes\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m postcode \u001b[38;5;129;01min\u001b[39;00m codes\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m63\u001b[39m:][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPostcode district\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# call the function and pass the empty DataFrame as an argument\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     df1 \u001b[38;5;241m=\u001b[39m \u001b[43mzoopla_rent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpostcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mZoopla\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# append the df1 DataFrame to the empty DataFrame\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, df1], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 27\u001b[0m, in \u001b[0;36mzoopla_rent\u001b[1;34m(postcodes, Trans_type, website, df)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Maximize the window\u001b[39;00m\n\u001b[0;32m     26\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize_window\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#Click the rent button\u001b[39;00m\n\u001b[0;32m     30\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1.5\u001b[39m)   \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:592\u001b[0m, in \u001b[0;36mWebDriver.maximize_window\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maximizes the current window that webdriver is using.\"\"\"\u001b[39;00m\n\u001b[0;32m    591\u001b[0m command \u001b[38;5;241m=\u001b[39m Command\u001b[38;5;241m.\u001b[39mW3C_MAXIMIZE_WINDOW\n\u001b[1;32m--> 592\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=113.0.5672.127)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x01088893+48451]\n\t(No symbol) [0x0101B8A1]\n\t(No symbol) [0x00F25058]\n\t(No symbol) [0x00F0D073]\n\t(No symbol) [0x00F6DEBB]\n\t(No symbol) [0x00F7BFD3]\n\t(No symbol) [0x00F6A0B6]\n\t(No symbol) [0x00F47E08]\n\t(No symbol) [0x00F48F2D]\n\tGetHandleVerifier [0x012E8E3A+2540266]\n\tGetHandleVerifier [0x01328959+2801161]\n\tGetHandleVerifier [0x0132295C+2776588]\n\tGetHandleVerifier [0x01112280+612144]\n\t(No symbol) [0x01024F6C]\n\t(No symbol) [0x010211D8]\n\t(No symbol) [0x010212BB]\n\t(No symbol) [0x01014857]\n\tBaseThreadInitThunk [0x750A00C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x76FE7B4E+286]\n\tRtlGetAppContainerNamedObjectPath [0x76FE7B1E+238]\n"
     ]
    }
   ],
   "source": [
    "# create an empty DataFrame outside the function\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# loop through postcodes\n",
    "for postcode in codes.loc[63:]['Postcode district']:\n",
    "    # call the function and pass the empty DataFrame as an argument\n",
    "    df1 = zoopla_rent(postcode, 'Rent', 'Zoopla', df)\n",
    "    # append the df1 DataFrame to the empty DataFrame\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "print('------------------------ WEB SCRAPING COMPLETED: OVERALL TOTAL NUMBER OF PROPERTIES SCRAPED IS ' + str(df.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c940ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Zoop_rent2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dcd63f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postcode district</th>\n",
       "      <th>Local Areas</th>\n",
       "      <th>Borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>HA2</td>\n",
       "      <td>North Harrow, South Harrow</td>\n",
       "      <td>Harrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>HA3</td>\n",
       "      <td>Harrow Weald, Kenton, Wealdstone</td>\n",
       "      <td>Harrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>HA4</td>\n",
       "      <td>Ruislip</td>\n",
       "      <td>Hillingdon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>HA5</td>\n",
       "      <td>Pinner, Eastcote, Hatch End, Carpenders Park</td>\n",
       "      <td>Harrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>HA6</td>\n",
       "      <td>Northwood, Moor Park, Sandy Lodge</td>\n",
       "      <td>Hillingdon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>WC2B</td>\n",
       "      <td>Drury Lane, Aldwych</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>WC2E</td>\n",
       "      <td>Covent Garden</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>WC2H</td>\n",
       "      <td>Leicester Square</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>WC2N</td>\n",
       "      <td>Charing Cross</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>WC2R</td>\n",
       "      <td>Somerset House</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Postcode district                                   Local Areas   \n",
       "63                HA2                    North Harrow, South Harrow  \\\n",
       "64                HA3              Harrow Weald, Kenton, Wealdstone   \n",
       "65                HA4                                       Ruislip   \n",
       "66                HA5  Pinner, Eastcote, Hatch End, Carpenders Park   \n",
       "67                HA6             Northwood, Moor Park, Sandy Lodge   \n",
       "..                ...                                           ...   \n",
       "263              WC2B                           Drury Lane, Aldwych   \n",
       "264              WC2E                                 Covent Garden   \n",
       "265              WC2H                              Leicester Square   \n",
       "266              WC2N                                 Charing Cross   \n",
       "267              WC2R                                Somerset House   \n",
       "\n",
       "         Borough  \n",
       "63        Harrow  \n",
       "64        Harrow  \n",
       "65    Hillingdon  \n",
       "66        Harrow  \n",
       "67    Hillingdon  \n",
       "..           ...  \n",
       "263       Camden  \n",
       "264  Westminster  \n",
       "265  Westminster  \n",
       "266  Westminster  \n",
       "267  Westminster  \n",
       "\n",
       "[205 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = codes.loc[63:]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d6027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
